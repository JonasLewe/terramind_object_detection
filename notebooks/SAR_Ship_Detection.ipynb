{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPli4FDbTsRS4+cEv8U+Bbt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonasLewe/terramind_object_detection/blob/main/notebooks/SAR_Ship_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daH8iHWV60Gc",
        "outputId": "f0ecab78-3ab2-4dfd-88ce-d46069a75a58"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install terratorch==1.1.1 gdown tensorboard > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "8KodReoWxiGy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import gdown\n",
        "import terratorch\n",
        "import albumentations\n",
        "import rasterio\n",
        "import json\n",
        "from collections import Counter\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightning.pytorch as pl\n",
        "import matplotlib.pyplot as plt\n",
        "import pyproj\n",
        "from pathlib import Path\n",
        "from terratorch.datamodules import GenericNonGeoSegmentationDataModule\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ24dhm6xmeL",
        "outputId": "16840abd-ed0a-466d-fe42-d21efeafd9f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "/usr/local/lib/python3.12/dist-packages/torch/amp/autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  _C._set_float32_matmul_precision(precision)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Dataset"
      ],
      "metadata": {
        "id": "LyZ7CDVviYNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/xview3/raw /content/xview3/chips /content/xview3/runs\n",
        "!mkdir -p /content/drive/MyDrive/xview3/{chips,runs,meta}"
      ],
      "metadata": {
        "id": "jLtq151L7JF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rsync -ah --info=progress2 /content/drive/MyDrive/xview3/raw/ /content/xview3/raw/"
      ],
      "metadata": {
        "id": "kxCIXevg6sZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!for f in /content/xview3/raw/*.tar.gz; do tar -xzvf \"$f\" -C /content/xview3/raw && rm \"$f\"; done"
      ],
      "metadata": {
        "id": "UkB1e8j29uNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/xview3/meta\n",
        "!cp /content/drive/MyDrive/xview3/meta/train.csv /content/xview3/meta/train.csv\n",
        "!cp /content/drive/MyDrive/xview3/meta/validation.csv /content/xview3/meta/validation.csv\n",
        "!ls -lah /content/xview3/meta"
      ],
      "metadata": {
        "id": "WsrALZmEAG8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Exploration"
      ],
      "metadata": {
        "id": "mzoQDJVVxvLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE = Path(\"/content/xview3\")\n",
        "RAW  = BASE / \"raw\"\n",
        "META = BASE / \"meta\"\n",
        "EXP  = BASE / \"explore\"\n",
        "CHIP = BASE / \"chips\"\n",
        "RUNS = BASE / \"runs\""
      ],
      "metadata": {
        "id": "NiMLJgpK2nIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_scenes(raw_dir: Path):\n",
        "    # scene folders are dirs containing VV_dB.tif + VH_dB.tif\n",
        "    scenes = []\n",
        "    for d in sorted(raw_dir.iterdir()):\n",
        "        if d.is_dir() and (d / \"VV_dB.tif\").exists() and (d / \"VH_dB.tif\").exists():\n",
        "            scenes.append(d.name)\n",
        "    return scenes\n",
        "\n",
        "scenes = list_scenes(RAW)\n",
        "print(f\"Found {len(scenes)} scenes under {RAW}\")\n",
        "print(\"First scenes:\", scenes[:10])\n"
      ],
      "metadata": {
        "id": "hUJBFUcM0sIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell: Dataset Overview\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "# Load metadata\n",
        "train_df = pd.read_csv(META / \"train.csv\")\n",
        "val_df = pd.read_csv(META / \"validation.csv\")\n",
        "\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"xView3 Dataset Overview\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "print(f\"Training samples: {len(train_df):,}\")\n",
        "print(f\"Validation samples: {len(val_df):,}\")\n",
        "print(f\"Total labels: {len(train_df) + len(val_df):,}\\n\")\n",
        "\n",
        "# Scene distribution\n",
        "train_scenes = train_df['scene_id'].nunique()\n",
        "val_scenes = val_df['scene_id'].nunique()\n",
        "print(f\"Training scenes: {train_scenes}\")\n",
        "print(f\"Validation scenes: {val_scenes}\\n\")\n",
        "\n",
        "# Class distribution (assuming 'is_vessel', 'is_fishing' columns)\n",
        "if 'is_vessel' in train_df.columns:\n",
        "    print(\"Class Distribution (Train):\")\n",
        "    print(f\"  Vessels: {train_df['is_vessel'].sum():,}\")\n",
        "    # Fix: Compare to 0 instead of using ~\n",
        "    print(f\"  Non-vessels: {(train_df['is_vessel'] == 0).sum():,}\")\n",
        "    if 'is_fishing' in train_df.columns:\n",
        "        # Fix: Boolean indexing requires bool or comparison\n",
        "        fishing = train_df[train_df['is_vessel'] == 1]['is_fishing'].sum()\n",
        "        print(f\"  Fishing vessels: {fishing:,}\")\n",
        "        print(f\"  Non-fishing vessels: {train_df['is_vessel'].sum() - fishing:,}\\n\")\n",
        "\n",
        "# Labels per scene\n",
        "labels_per_scene = train_df.groupby('scene_id').size()\n",
        "print(f\"Labels per scene (train):\")\n",
        "print(f\"  Mean: {labels_per_scene.mean():.1f}\")\n",
        "print(f\"  Median: {labels_per_scene.median():.1f}\")\n",
        "print(f\"  Min/Max: {labels_per_scene.min()} / {labels_per_scene.max()}\")"
      ],
      "metadata": {
        "id": "UTrFIbqCCU4X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5f97ebb-95c8-4826-9a64-1857d7688112"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "xView3 Dataset Overview\n",
            "============================================================\n",
            "\n",
            "Training samples: 64,113\n",
            "Validation samples: 19,224\n",
            "Total labels: 83,337\n",
            "\n",
            "Training scenes: 554\n",
            "Validation scenes: 50\n",
            "\n",
            "Class Distribution (Train):\n",
            "  Vessels: 36,375\n",
            "  Non-vessels: 16,692\n",
            "  Fishing vessels: 12,510\n",
            "  Non-fishing vessels: 23,865\n",
            "\n",
            "Labels per scene (train):\n",
            "  Mean: 115.7\n",
            "  Median: 84.5\n",
            "  Min/Max: 26 / 435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization Helper Functions"
      ],
      "metadata": {
        "id": "irb8wOakHTAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_sar_scene(scene_dir: Path, bands=[\"VV\", \"VH\"]):\n",
        "    \"\"\"Load VV and VH bands from scene directory\"\"\"\n",
        "    data = {}\n",
        "    for band in bands:\n",
        "        path = scene_dir / f\"{band}_dB.tif\"\n",
        "        with rasterio.open(path) as src:\n",
        "            data[band] = src.read(1).astype(\"float32\")\n",
        "            if band == bands[0]:  # Store metadata from first band\n",
        "                data['meta'] = {\n",
        "                    'transform': src.transform,\n",
        "                    'crs': src.crs,\n",
        "                    'bounds': src.bounds,\n",
        "                    'shape': src.shape\n",
        "                }\n",
        "    return data\n",
        "\n",
        "def sar_to_rgb(vv, vh, percentile_clip=(2, 98)):\n",
        "    \"\"\"\n",
        "    Create RGB composite from SAR dual-pol data\n",
        "    R = VV, G = VH, B = VV/VH ratio (cross-pol)\n",
        "    \"\"\"\n",
        "    # Clip outliers\n",
        "    vv_clip = np.nanpercentile(vv, percentile_clip)\n",
        "    vh_clip = np.nanpercentile(vh, percentile_clip)\n",
        "\n",
        "    vv_norm = np.clip((vv - vv_clip[0]) / (vv_clip[1] - vv_clip[0] + 1e-6), 0, 1)\n",
        "    vh_norm = np.clip((vh - vh_clip[0]) / (vh_clip[1] - vh_clip[0] + 1e-6), 0, 1)\n",
        "\n",
        "    # Cross-pol ratio (indicator for surface roughness)\n",
        "    ratio = np.where(vh != 0, vv / (vh + 1e-6), 0)\n",
        "    ratio_clip = np.nanpercentile(ratio[np.isfinite(ratio)], percentile_clip)\n",
        "    ratio_norm = np.clip((ratio - ratio_clip[0]) / (ratio_clip[1] - ratio_clip[0] + 1e-6), 0, 1)\n",
        "\n",
        "    rgb = np.stack([vv_norm, vh_norm, ratio_norm], axis=-1)\n",
        "    return rgb\n",
        "\n",
        "def latlon_to_pixel(lats, lons, transform, crs):\n",
        "    \"\"\"Convert lat/lon to pixel coordinates\"\"\"\n",
        "    transformer = pyproj.Transformer.from_crs(\"EPSG:4326\", crs, always_xy=True)\n",
        "    xs, ys = transformer.transform(lons, lats)\n",
        "\n",
        "    # Rasterio transform: pixel = ~transform * (x, y)\n",
        "    inv_transform = ~transform\n",
        "    pixels = [inv_transform * (x, y) for x, y in zip(xs, ys)]\n",
        "    cols = np.array([p[0] for p in pixels], dtype=int)\n",
        "    rows = np.array([p[1] for p in pixels], dtype=int)\n",
        "\n",
        "    return rows, cols\n",
        "\n",
        "def plot_sar_with_labels(scene_id, df, raw_dir=RAW, window_size=1024, max_labels=None):\n",
        "    \"\"\"\n",
        "    Plot SAR scene with overlaid labels\n",
        "    \"\"\"\n",
        "    scene_dir = raw_dir / scene_id\n",
        "    scene_labels = df[df['scene_id'] == scene_id].copy()\n",
        "\n",
        "    if max_labels:\n",
        "        scene_labels = scene_labels.head(max_labels)\n",
        "\n",
        "    # Load SAR data\n",
        "    sar_data = load_sar_scene(scene_dir)\n",
        "    vv, vh = sar_data['VV'], sar_data['VH']\n",
        "    meta = sar_data['meta']\n",
        "\n",
        "    # Convert labels to pixels\n",
        "    rows, cols = latlon_to_pixel(\n",
        "        scene_labels['detect_lat'].values,\n",
        "        scene_labels['detect_lon'].values,\n",
        "        meta['transform'],\n",
        "        meta['crs']\n",
        "    )\n",
        "\n",
        "    # Create RGB composite\n",
        "    rgb = sar_to_rgb(vv, vh)\n",
        "\n",
        "    # Plot\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "    # VV band\n",
        "    axes[0].imshow(vv, cmap='gray', vmin=np.nanpercentile(vv, 2), vmax=np.nanpercentile(vv, 98))\n",
        "    axes[0].scatter(cols, rows, c='red', s=30, marker='x', alpha=0.7, linewidths=2)\n",
        "    axes[0].set_title(f'VV (dB) - {len(scene_labels)} labels')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # VH band\n",
        "    axes[1].imshow(vh, cmap='gray', vmin=np.nanpercentile(vh, 2), vmax=np.nanpercentile(vh, 98))\n",
        "    axes[1].scatter(cols, rows, c='red', s=30, marker='x', alpha=0.7, linewidths=2)\n",
        "    axes[1].set_title('VH (dB)')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # RGB Composite\n",
        "    axes[2].imshow(rgb)\n",
        "    axes[2].scatter(cols, rows, c='cyan', s=30, marker='x', alpha=0.8, linewidths=2)\n",
        "    axes[2].set_title('RGB Composite (VV/VH/Ratio)')\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.suptitle(f'Scene: {scene_id} | Shape: {meta[\"shape\"]}', fontsize=14, y=0.98)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print stats\n",
        "    print(f\"\\nScene Stats:\")\n",
        "    print(f\"  VV range: [{np.nanmin(vv):.2f}, {np.nanmax(vv):.2f}] dB\")\n",
        "    print(f\"  VH range: [{np.nanmin(vh):.2f}, {np.nanmax(vh):.2f}] dB\")\n",
        "    print(f\"  Labels in scene: {len(scene_labels)}\")\n",
        "    print(f\"  Image shape: {meta['shape']}\")"
      ],
      "metadata": {
        "id": "hAmquOapGgVn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell: Detailed Scene Exploration\n",
        "\n",
        "# Pick a scene with reasonable number of labels\n",
        "scene_counts = train_df['scene_id'].value_counts()\n",
        "selected_scene = scene_counts[scene_counts.between(10, 100)].index[0]\n",
        "\n",
        "selected_scene = \"05bc615a9b0e1159t\"\n",
        "print(f\"Analyzing scene: {selected_scene}\")\n",
        "plot_sar_with_labels(selected_scene, train_df, max_labels=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kftggje0HOev",
        "outputId": "8b0d6095-75b0-4243-9718-78ba6943678a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing scene: 05bc615a9b0e1159t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell: Multi-Scene Gallery\n",
        "\n",
        "# Select diverse scenes (different label counts)\n",
        "scene_counts = train_df['scene_id'].value_counts()\n",
        "low_count = scene_counts[scene_counts < 10].index[:2]\n",
        "mid_count = scene_counts[scene_counts.between(10, 50)].index[:2]\n",
        "high_count = scene_counts[scene_counts > 50].index[:2]\n",
        "\n",
        "gallery_scenes = list(low_count) + list(mid_count) + list(high_count)\n",
        "\n",
        "for scene_id in gallery_scenes[:6]:  # Show first 6\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    plot_sar_with_labels(scene_id, train_df, max_labels=30)"
      ],
      "metadata": {
        "id": "hfaRezZfHda6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell: Zoomed-in Label Chips\n",
        "\n",
        "def extract_chip(vv, vh, row, col, chip_size=128):\n",
        "    \"\"\"Extract a chip centered on (row, col)\"\"\"\n",
        "    r_start = max(0, row - chip_size // 2)\n",
        "    r_end = min(vv.shape[0], row + chip_size // 2)\n",
        "    c_start = max(0, col - chip_size // 2)\n",
        "    c_end = min(vv.shape[1], col + chip_size // 2)\n",
        "\n",
        "    vv_chip = vv[r_start:r_end, c_start:c_end]\n",
        "    vh_chip = vh[r_start:r_end, c_start:c_end]\n",
        "\n",
        "    return vv_chip, vh_chip, (r_start, c_start)\n",
        "\n",
        "def plot_label_chips(scene_id, df, n_chips=9, chip_size=128):\n",
        "    \"\"\"Plot grid of zoomed-in chips around labels\"\"\"\n",
        "    scene_labels = df[df['scene_id'] == scene_id].sample(min(n_chips, len(df[df['scene_id'] == scene_id])))\n",
        "\n",
        "    scene_dir = RAW / scene_id\n",
        "    sar_data = load_sar_scene(scene_dir)\n",
        "    vv, vh = sar_data['VV'], sar_data['VH']\n",
        "    meta = sar_data['meta']\n",
        "\n",
        "    rows, cols = latlon_to_pixel(\n",
        "        scene_labels['detect_lat'].values,\n",
        "        scene_labels['detect_lon'].values,\n",
        "        meta['transform'],\n",
        "        meta['crs']\n",
        "    )\n",
        "\n",
        "    n_cols = 3\n",
        "    n_rows = (len(scene_labels) + n_cols - 1) // n_cols\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 4*n_rows))\n",
        "    axes = axes.flatten() if n_rows > 1 else [axes]\n",
        "\n",
        "    for idx, (row, col) in enumerate(zip(rows, cols)):\n",
        "        vv_chip, vh_chip, offset = extract_chip(vv, vh, row, col, chip_size)\n",
        "        rgb_chip = sar_to_rgb(vv_chip, vh_chip)\n",
        "\n",
        "        # Center marker\n",
        "        center = (chip_size // 2, chip_size // 2)\n",
        "\n",
        "        axes[idx].imshow(rgb_chip)\n",
        "        axes[idx].scatter([center[1]], [center[0]], c='red', s=100, marker='+', linewidths=3)\n",
        "        axes[idx].set_title(f'Label {idx+1}', fontsize=10)\n",
        "        axes[idx].axis('off')\n",
        "\n",
        "    # Hide empty subplots\n",
        "    for idx in range(len(scene_labels), len(axes)):\n",
        "        axes[idx].axis('off')\n",
        "\n",
        "    plt.suptitle(f'Label Chips from {scene_id}', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Run for selected scene\n",
        "plot_label_chips(selected_scene, train_df, n_chips=9, chip_size=192)"
      ],
      "metadata": {
        "id": "jMGsgEjoIgc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell: Data Quality Analysis\n",
        "\n",
        "def analyze_data_quality(df, scene_sample=10):\n",
        "    \"\"\"Check for data quality issues\"\"\"\n",
        "    print(f\"{'='*60}\")\n",
        "    print(\"Data Quality Checks\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # 1. Missing values\n",
        "    print(\"Missing Values:\")\n",
        "    print(df.isnull().sum())\n",
        "    print()\n",
        "\n",
        "    # 2. Coordinate ranges\n",
        "    print(\"Coordinate Ranges:\")\n",
        "    print(f\"  Latitude: [{df['detect_lat'].min():.4f}, {df['detect_lat'].max():.4f}]\")\n",
        "    print(f\"  Longitude: [{df['detect_lon'].min():.4f}, {df['detect_lon'].max():.4f}]\")\n",
        "    print()\n",
        "\n",
        "    # 3. Sample scenes for image quality\n",
        "    sample_scenes = df['scene_id'].value_counts().head(scene_sample).index\n",
        "\n",
        "    vv_ranges, vh_ranges = [], []\n",
        "    nan_counts = []\n",
        "\n",
        "    for scene_id in sample_scenes:\n",
        "        scene_dir = RAW / scene_id\n",
        "        if not scene_dir.exists():\n",
        "            continue\n",
        "\n",
        "        sar_data = load_sar_scene(scene_dir)\n",
        "        vv, vh = sar_data['VV'], sar_data['VH']\n",
        "\n",
        "        vv_ranges.append((np.nanmin(vv), np.nanmax(vv)))\n",
        "        vh_ranges.append((np.nanmin(vh), np.nanmax(vh)))\n",
        "        nan_counts.append((np.isnan(vv).sum(), np.isnan(vh).sum()))\n",
        "\n",
        "    print(f\"SAR Value Ranges (sampled {len(vv_ranges)} scenes):\")\n",
        "    vv_mins, vv_maxs = zip(*vv_ranges)\n",
        "    vh_mins, vh_maxs = zip(*vh_ranges)\n",
        "    print(f\"  VV: [{np.mean(vv_mins):.2f}, {np.mean(vv_maxs):.2f}] dB (avg)\")\n",
        "    print(f\"  VH: [{np.mean(vh_mins):.2f}, {np.mean(vh_maxs):.2f}] dB (avg)\")\n",
        "    print(f\"  NaN pixels (VV): {np.mean([n[0] for n in nan_counts]):.0f} avg\")\n",
        "    print(f\"  NaN pixels (VH): {np.mean([n[1] for n in nan_counts]):.0f} avg\")\n",
        "\n",
        "analyze_data_quality(train_df, scene_sample=10)"
      ],
      "metadata": {
        "id": "PUbyZuDTIi7V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}