{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonasLewe/terramind_object_detection/blob/main/notebooks/SAR_Ship_Detection_optimized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "metadata": {
        "id": "daH8iHWV60Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install terratorch==1.1.1 gdown tensorboard > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "8KodReoWxiGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import torch\n",
        "import gdown\n",
        "import terratorch\n",
        "import albumentations\n",
        "import rasterio\n",
        "import rasterio.windows\n",
        "import rasterio.enums\n",
        "import json\n",
        "from collections import Counter\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightning.pytorch as pl\n",
        "import matplotlib.pyplot as plt\n",
        "import pyproj\n",
        "from pathlib import Path\n",
        "from terratorch.datamodules import GenericNonGeoSegmentationDataModule\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "JJ24dhm6xmeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Dataset"
      ],
      "metadata": {
        "id": "LyZ7CDVviYNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/xview3/raw /content/xview3/chips /content/xview3/runs\n",
        "!mkdir -p /content/drive/MyDrive/xview3/{chips,runs,meta}"
      ],
      "metadata": {
        "id": "jLtq151L7JF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rsync -ah --info=progress2 /content/drive/MyDrive/xview3/raw/ /content/xview3/raw/"
      ],
      "metadata": {
        "id": "kxCIXevg6sZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!for f in /content/xview3/raw/*.tar.gz; do tar -xzvf \"$f\" -C /content/xview3/raw && rm \"$f\"; done"
      ],
      "metadata": {
        "id": "UkB1e8j29uNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/xview3/meta\n",
        "!cp /content/drive/MyDrive/xview3/meta/train.csv /content/xview3/meta/train.csv\n",
        "!cp /content/drive/MyDrive/xview3/meta/validation.csv /content/xview3/meta/validation.csv\n",
        "!ls -lah /content/xview3/meta"
      ],
      "metadata": {
        "id": "WsrALZmEAG8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Exploration"
      ],
      "metadata": {
        "id": "mzoQDJVVxvLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE = Path(\"/content/xview3\")\n",
        "RAW  = BASE / \"raw\"\n",
        "META = BASE / \"meta\"\n",
        "EXP  = BASE / \"explore\"\n",
        "CHIP = BASE / \"chips\"\n",
        "RUNS = BASE / \"runs\"\n",
        "\n",
        "# Memory-saving: Downsample factor for overview plots\n",
        "DOWNSAMPLE_FACTOR = 8"
      ],
      "metadata": {
        "id": "NiMLJgpK2nIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_scenes(raw_dir: Path):\n",
        "    \"\"\"Detect scene folders containing VV_dB.tif + VH_dB.tif\"\"\"\n",
        "    scenes = []\n",
        "    if not raw_dir.exists():\n",
        "        print(f\"Warning: {raw_dir} does not exist\")\n",
        "        return scenes\n",
        "\n",
        "    for d in sorted(raw_dir.iterdir()):\n",
        "        if d.is_dir() and (d / \"VV_dB.tif\").exists() and (d / \"VH_dB.tif\").exists():\n",
        "            scenes.append(d.name)\n",
        "    return scenes\n",
        "\n",
        "scenes = list_scenes(RAW)\n",
        "print(f\"Found {len(scenes)} scenes under {RAW}\")\n",
        "print(\"First scenes:\", scenes[:10])\n"
      ],
      "metadata": {
        "id": "hUJBFUcM0sIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell: Dataset Overview\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "# Load metadata\n",
        "train_df = pd.read_csv(META / \"train.csv\")\n",
        "val_df = pd.read_csv(META / \"validation.csv\")\n",
        "\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"xView3 Dataset Overview\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "print(f\"Training samples: {len(train_df):,}\")\n",
        "print(f\"Validation samples: {len(val_df):,}\")\n",
        "print(f\"Total labels: {len(train_df) + len(val_df):,}\\n\")\n",
        "\n",
        "# Scene distribution\n",
        "train_scenes = train_df['scene_id'].nunique()\n",
        "val_scenes = val_df['scene_id'].nunique()\n",
        "print(f\"Training scenes: {train_scenes}\")\n",
        "print(f\"Validation scenes: {val_scenes}\\n\")\n",
        "\n",
        "# Class distribution (assuming 'is_vessel', 'is_fishing' columns)\n",
        "if 'is_vessel' in train_df.columns:\n",
        "    print(\"Class Distribution (Train):\")\n",
        "    print(f\"  Vessels: {train_df['is_vessel'].sum():,}\")\n",
        "    # Fix: Compare to 0 instead of using ~\n",
        "    print(f\"  Non-vessels: {(train_df['is_vessel'] == 0).sum():,}\")\n",
        "    if 'is_fishing' in train_df.columns:\n",
        "        # Fix: Boolean indexing requires bool or comparison\n",
        "        fishing = train_df[train_df['is_vessel'] == 1]['is_fishing'].sum()\n",
        "        print(f\"  Fishing vessels: {fishing:,}\")\n",
        "        print(f\"  Non-fishing vessels: {train_df['is_vessel'].sum() - fishing:,}\\n\")\n",
        "\n",
        "# Labels per scene\n",
        "labels_per_scene = train_df.groupby('scene_id').size()\n",
        "print(f\"Labels per scene (train):\")\n",
        "print(f\"  Mean: {labels_per_scene.mean():.1f}\")\n",
        "print(f\"  Median: {labels_per_scene.median():.1f}\")\n",
        "print(f\"  Min/Max: {labels_per_scene.min()} / {labels_per_scene.max()}\")"
      ],
      "metadata": {
        "id": "UTrFIbqCCU4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization Helper Functions"
      ],
      "metadata": {
        "id": "irb8wOakHTAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_sar_scene(scene_dir: Path, bands=[\"VV\", \"VH\"],\n",
        "                   downsample=1, window=None):\n",
        "    \"\"\"\n",
        "    Load VV and VH bands from scene directory.\n",
        "\n",
        "    Args:\n",
        "        scene_dir: Path to scene folder\n",
        "        bands: List of bands to load\n",
        "        downsample: Factor for downsampling (e.g., 8 = 1/8 resolution)\n",
        "        window: rasterio.windows.Window for chip extraction (overrides downsample)\n",
        "\n",
        "    Returns:\n",
        "        dict with band data and metadata\n",
        "    \"\"\"\n",
        "    data = {}\n",
        "    for band in bands:\n",
        "        path = scene_dir / f\"{band}_dB.tif\"\n",
        "        with rasterio.open(path) as src:\n",
        "            if window is not None:\n",
        "                # Read specific window only (for chips)\n",
        "                data[band] = src.read(1, window=window).astype(\"float32\")\n",
        "                if band == bands[0]:\n",
        "                    data['meta'] = {\n",
        "                        'transform': src.window_transform(window),\n",
        "                        'crs': src.crs,\n",
        "                        'bounds': src.bounds,\n",
        "                        'shape': src.shape,\n",
        "                        'loaded_shape': data[band].shape\n",
        "                    }\n",
        "            elif downsample > 1:\n",
        "                # Read downsampled for overview plots\n",
        "                h, w = src.height // downsample, src.width // downsample\n",
        "                data[band] = src.read(\n",
        "                    1,\n",
        "                    out_shape=(h, w),\n",
        "                    resampling=rasterio.enums.Resampling.average\n",
        "                ).astype(\"float32\")\n",
        "                if band == bands[0]:\n",
        "                    # Adjust transform for downsampled data\n",
        "                    data['meta'] = {\n",
        "                        'transform': src.transform * src.transform.scale(\n",
        "                            src.width / w,\n",
        "                            src.height / h\n",
        "                        ),\n",
        "                        'crs': src.crs,\n",
        "                        'bounds': src.bounds,\n",
        "                        'shape': src.shape,\n",
        "                        'loaded_shape': (h, w),\n",
        "                        'downsample': downsample\n",
        "                    }\n",
        "            else:\n",
        "                # Full resolution (WARNING: high RAM usage!)\n",
        "                data[band] = src.read(1).astype(\"float32\")\n",
        "                if band == bands[0]:\n",
        "                    data['meta'] = {\n",
        "                        'transform': src.transform,\n",
        "                        'crs': src.crs,\n",
        "                        'bounds': src.bounds,\n",
        "                        'shape': src.shape,\n",
        "                        'loaded_shape': src.shape\n",
        "                    }\n",
        "    return data\n",
        "\n",
        "def sar_to_rgb(vv, vh, percentile_clip=(2, 98)):\n",
        "    \"\"\"\n",
        "    Create RGB composite from SAR dual-pol data\n",
        "    R = VV, G = VH, B = VV/VH ratio (cross-pol)\n",
        "    \"\"\"\n",
        "    # Clip outliers\n",
        "    vv_clip = np.nanpercentile(vv, percentile_clip)\n",
        "    vh_clip = np.nanpercentile(vh, percentile_clip)\n",
        "\n",
        "    vv_norm = np.clip((vv - vv_clip[0]) / (vv_clip[1] - vv_clip[0] + 1e-6), 0, 1)\n",
        "    vh_norm = np.clip((vh - vh_clip[0]) / (vh_clip[1] - vh_clip[0] + 1e-6), 0, 1)\n",
        "\n",
        "    # Cross-pol ratio (indicator for surface roughness)\n",
        "    ratio = np.where(vh != 0, vv / (vh + 1e-6), 0)\n",
        "    ratio_clip = np.nanpercentile(ratio[np.isfinite(ratio)], percentile_clip)\n",
        "    ratio_norm = np.clip((ratio - ratio_clip[0]) / (ratio_clip[1] - ratio_clip[0] + 1e-6), 0, 1)\n",
        "\n",
        "    rgb = np.stack([vv_norm, vh_norm, ratio_norm], axis=-1)\n",
        "    return rgb\n",
        "\n",
        "def latlon_to_pixel(lats, lons, transform, crs, downsample=1):\n",
        "    \"\"\"\n",
        "    Convert lat/lon to pixel coordinates.\n",
        "\n",
        "    Args:\n",
        "        downsample: If image was downsampled, adjust pixel coords accordingly\n",
        "    \"\"\"\n",
        "    transformer = pyproj.Transformer.from_crs(\"EPSG:4326\", crs, always_xy=True)\n",
        "    xs, ys = transformer.transform(lons, lats)\n",
        "\n",
        "    # Rasterio transform: pixel = ~transform * (x, y)\n",
        "    inv_transform = ~transform\n",
        "    pixels = [inv_transform * (x, y) for x, y in zip(xs, ys)]\n",
        "    cols = np.array([p[0] for p in pixels], dtype=int)\n",
        "    rows = np.array([p[1] for p in pixels], dtype=int)\n",
        "\n",
        "    # Adjust for downsampling\n",
        "    if downsample > 1:\n",
        "        cols = cols // downsample\n",
        "        rows = rows // downsample\n",
        "\n",
        "    return rows, cols\n",
        "\n",
        "def plot_sar_with_labels(scene_id, df, raw_dir=RAW, max_labels=None, downsample=DOWNSAMPLE_FACTOR):\n",
        "    \"\"\"\n",
        "    Plot SAR scene with overlaid labels (memory-efficient with downsampling)\n",
        "    \"\"\"\n",
        "    scene_dir = raw_dir / scene_id\n",
        "    scene_labels = df[df['scene_id'] == scene_id].copy()\n",
        "\n",
        "    if max_labels:\n",
        "        scene_labels = scene_labels.head(max_labels)\n",
        "\n",
        "    # Load SAR data with downsampling for memory efficiency\n",
        "    sar_data = load_sar_scene(scene_dir, downsample=downsample)\n",
        "    vv, vh = sar_data['VV'], sar_data['VH']\n",
        "    meta = sar_data['meta']\n",
        "\n",
        "    # Convert labels to pixels (using original transform, then scale)\n",
        "    with rasterio.open(scene_dir / \"VV_dB.tif\") as src:\n",
        "        orig_transform = src.transform\n",
        "        orig_crs = src.crs\n",
        "\n",
        "    rows, cols = latlon_to_pixel(\n",
        "        scene_labels['detect_lat'].values,\n",
        "        scene_labels['detect_lon'].values,\n",
        "        orig_transform,\n",
        "        orig_crs,\n",
        "        downsample=downsample\n",
        "    )\n",
        "\n",
        "    # Create RGB composite\n",
        "    rgb = sar_to_rgb(vv, vh)\n",
        "\n",
        "    # Plot\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "    # VV band\n",
        "    axes[0].imshow(vv, cmap='gray', vmin=np.nanpercentile(vv, 2), vmax=np.nanpercentile(vv, 98))\n",
        "    axes[0].scatter(cols, rows, c='red', s=30, marker='x', alpha=0.7, linewidths=2)\n",
        "    axes[0].set_title(f'VV (dB) - {len(scene_labels)} labels')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # VH band\n",
        "    axes[1].imshow(vh, cmap='gray', vmin=np.nanpercentile(vh, 2), vmax=np.nanpercentile(vh, 98))\n",
        "    axes[1].scatter(cols, rows, c='red', s=30, marker='x', alpha=0.7, linewidths=2)\n",
        "    axes[1].set_title('VH (dB)')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # RGB Composite\n",
        "    axes[2].imshow(rgb)\n",
        "    axes[2].scatter(cols, rows, c='cyan', s=30, marker='x', alpha=0.8, linewidths=2)\n",
        "    axes[2].set_title('RGB Composite (VV/VH/Ratio)')\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    ds_info = f\" (1/{downsample} res)\" if downsample > 1 else \"\"\n",
        "    plt.suptitle(f'Scene: {scene_id} | Original: {meta[\"shape\"]}{ds_info}', fontsize=14, y=0.98)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print stats\n",
        "    print(f\"\\nScene Stats:\")\n",
        "    print(f\"  VV range: [{np.nanmin(vv):.2f}, {np.nanmax(vv):.2f}] dB\")\n",
        "    print(f\"  VH range: [{np.nanmin(vh):.2f}, {np.nanmax(vh):.2f}] dB\")\n",
        "    print(f\"  Labels in scene: {len(scene_labels)}\")\n",
        "    print(f\"  Loaded shape: {meta['loaded_shape']}\")\n",
        "\n",
        "    # Cleanup\n",
        "    del sar_data, vv, vh, rgb\n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "hAmquOapGgVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell: Detailed Scene Exploration\n",
        "\n",
        "# Pick a scene with reasonable number of labels (automatic selection)\n",
        "scene_counts = train_df['scene_id'].value_counts()\n",
        "\n",
        "# Filter to scenes that actually exist in RAW folder\n",
        "available_scenes = set(scenes)\n",
        "valid_scene_counts = scene_counts[scene_counts.index.isin(available_scenes)]\n",
        "\n",
        "# Select scene with 10-100 labels\n",
        "candidates = valid_scene_counts[valid_scene_counts.between(10, 100)]\n",
        "if len(candidates) > 0:\n",
        "    selected_scene = candidates.index[0]\n",
        "else:\n",
        "    # Fallback to any available scene\n",
        "    selected_scene = valid_scene_counts.index[0]\n",
        "\n",
        "print(f\"Analyzing scene: {selected_scene} ({valid_scene_counts[selected_scene]} labels)\")\n",
        "plot_sar_with_labels(selected_scene, train_df, max_labels=50)"
      ],
      "metadata": {
        "id": "Kftggje0HOev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell: Multi-Scene Gallery\n",
        "\n",
        "# Filter scene_counts to only available scenes\n",
        "available_scenes = set(scenes)\n",
        "valid_scene_counts = scene_counts[scene_counts.index.isin(available_scenes)]\n",
        "\n",
        "# Select diverse scenes (different label counts)\n",
        "low_count = valid_scene_counts[valid_scene_counts < 10].index[:2]\n",
        "mid_count = valid_scene_counts[valid_scene_counts.between(10, 50)].index[:2]\n",
        "high_count = valid_scene_counts[valid_scene_counts > 50].index[:2]\n",
        "\n",
        "gallery_scenes = list(low_count) + list(mid_count) + list(high_count)\n",
        "\n",
        "for scene_id in gallery_scenes[:6]:  # Show first 6\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    plot_sar_with_labels(scene_id, train_df, max_labels=30)"
      ],
      "metadata": {
        "id": "hfaRezZfHda6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell: Zoomed-in Label Chips (Memory-efficient with windowed reads)\n",
        "\n",
        "def plot_label_chips(scene_id, df, n_chips=9, chip_size=128):\n",
        "    \"\"\"Plot grid of zoomed-in chips around labels using windowed reads\"\"\"\n",
        "    scene_labels_full = df[df['scene_id'] == scene_id]\n",
        "    scene_labels = scene_labels_full.sample(min(n_chips, len(scene_labels_full)))\n",
        "\n",
        "    scene_dir = RAW / scene_id\n",
        "    vv_path = scene_dir / \"VV_dB.tif\"\n",
        "    vh_path = scene_dir / \"VH_dB.tif\"\n",
        "\n",
        "    # Open files once, read chips as needed\n",
        "    with rasterio.open(vv_path) as vv_src, rasterio.open(vh_path) as vh_src:\n",
        "        transform = vv_src.transform\n",
        "        crs = vv_src.crs\n",
        "        img_height, img_width = vv_src.height, vv_src.width\n",
        "\n",
        "        # Convert labels to pixels\n",
        "        rows, cols = latlon_to_pixel(\n",
        "            scene_labels['detect_lat'].values,\n",
        "            scene_labels['detect_lon'].values,\n",
        "            transform,\n",
        "            crs\n",
        "        )\n",
        "\n",
        "        n_cols_plot = 3\n",
        "        n_rows_plot = (len(scene_labels) + n_cols_plot - 1) // n_cols_plot\n",
        "        fig, axes = plt.subplots(n_rows_plot, n_cols_plot, figsize=(12, 4*n_rows_plot))\n",
        "        axes = np.array(axes).flatten() if n_rows_plot > 1 else [axes] if n_rows_plot == 1 else axes\n",
        "\n",
        "        for idx, (row, col) in enumerate(zip(rows, cols)):\n",
        "            # Calculate window bounds with boundary checks\n",
        "            half = chip_size // 2\n",
        "            c_start = max(0, col - half)\n",
        "            r_start = max(0, row - half)\n",
        "            c_end = min(img_width, col + half)\n",
        "            r_end = min(img_height, row + half)\n",
        "\n",
        "            window = rasterio.windows.Window(\n",
        "                col_off=c_start,\n",
        "                row_off=r_start,\n",
        "                width=c_end - c_start,\n",
        "                height=r_end - r_start\n",
        "            )\n",
        "\n",
        "            # Read only the chip (memory efficient!)\n",
        "            vv_chip = vv_src.read(1, window=window).astype(\"float32\")\n",
        "            vh_chip = vh_src.read(1, window=window).astype(\"float32\")\n",
        "            rgb_chip = sar_to_rgb(vv_chip, vh_chip)\n",
        "\n",
        "            # Center marker (relative to chip)\n",
        "            center_col = col - c_start\n",
        "            center_row = row - r_start\n",
        "\n",
        "            axes[idx].imshow(rgb_chip)\n",
        "            axes[idx].scatter([center_col], [center_row], c='red', s=100, marker='+', linewidths=3)\n",
        "            axes[idx].set_title(f'Label {idx+1}', fontsize=10)\n",
        "            axes[idx].axis('off')\n",
        "\n",
        "        # Hide empty subplots\n",
        "        for idx in range(len(scene_labels), len(axes)):\n",
        "            axes[idx].axis('off')\n",
        "\n",
        "    plt.suptitle(f'Label Chips from {scene_id}', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "# Run for selected scene\n",
        "plot_label_chips(selected_scene, train_df, n_chips=9, chip_size=192)"
      ],
      "metadata": {
        "id": "jMGsgEjoIgc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell: Data Quality Analysis (Memory-efficient sampling)\n",
        "\n",
        "def analyze_data_quality(df, scene_sample=10):\n",
        "    \"\"\"Check for data quality issues using memory-efficient sampling\"\"\"\n",
        "    print(f\"{'='*60}\")\n",
        "    print(\"Data Quality Checks\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # 1. Missing values\n",
        "    print(\"Missing Values:\")\n",
        "    print(df.isnull().sum())\n",
        "    print()\n",
        "\n",
        "    # 2. Coordinate ranges\n",
        "    print(\"Coordinate Ranges:\")\n",
        "    print(f\"  Latitude: [{df['detect_lat'].min():.4f}, {df['detect_lat'].max():.4f}]\")\n",
        "    print(f\"  Longitude: [{df['detect_lon'].min():.4f}, {df['detect_lon'].max():.4f}]\")\n",
        "    print()\n",
        "\n",
        "    # 3. Sample scenes for image quality (memory efficient)\n",
        "    available_scenes = set(scenes)\n",
        "    sample_scene_ids = df['scene_id'].value_counts().head(scene_sample * 2).index\n",
        "    sample_scene_ids = [s for s in sample_scene_ids if s in available_scenes][:scene_sample]\n",
        "\n",
        "    vv_ranges, vh_ranges = [], []\n",
        "    nan_counts = []\n",
        "\n",
        "    print(f\"Sampling {len(sample_scene_ids)} scenes for statistics...\")\n",
        "\n",
        "    for scene_id in sample_scene_ids:\n",
        "        scene_dir = RAW / scene_id\n",
        "        if not scene_dir.exists():\n",
        "            continue\n",
        "\n",
        "        # Memory-efficient: read downsampled version\n",
        "        sar_data = load_sar_scene(scene_dir, downsample=16)  # Very small for stats\n",
        "        vv, vh = sar_data['VV'], sar_data['VH']\n",
        "\n",
        "        vv_ranges.append((np.nanmin(vv), np.nanmax(vv)))\n",
        "        vh_ranges.append((np.nanmin(vh), np.nanmax(vh)))\n",
        "        nan_counts.append((np.isnan(vv).sum(), np.isnan(vh).sum()))\n",
        "\n",
        "        del sar_data, vv, vh\n",
        "        gc.collect()\n",
        "\n",
        "    if vv_ranges:\n",
        "        print(f\"\\nSAR Value Ranges (sampled {len(vv_ranges)} scenes):\")\n",
        "        vv_mins, vv_maxs = zip(*vv_ranges)\n",
        "        vh_mins, vh_maxs = zip(*vh_ranges)\n",
        "        print(f\"  VV: [{np.mean(vv_mins):.2f}, {np.mean(vv_maxs):.2f}] dB (avg)\")\n",
        "        print(f\"  VH: [{np.mean(vh_mins):.2f}, {np.mean(vh_maxs):.2f}] dB (avg)\")\n",
        "        print(f\"  NaN pixels (VV): {np.mean([n[0] for n in nan_counts]):.0f} avg (in downsampled)\")\n",
        "        print(f\"  NaN pixels (VH): {np.mean([n[1] for n in nan_counts]):.0f} avg (in downsampled)\")\n",
        "\n",
        "analyze_data_quality(train_df, scene_sample=10)"
      ],
      "metadata": {
        "id": "PUbyZuDTIi7V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}